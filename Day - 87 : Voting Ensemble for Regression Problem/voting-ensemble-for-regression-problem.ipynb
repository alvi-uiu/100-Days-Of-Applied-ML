{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nfrom sklearn.datasets import fetch_california_housing\nX,y = fetch_california_housing(return_X_y=True)\n\n\n# Select only the first 700 samples (to reduce time for showing example only )\nX = X[:700]\ny = y[:700]\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:10:23.839896Z","iopub.execute_input":"2025-01-31T06:10:23.840223Z","iopub.status.idle":"2025-01-31T06:10:23.854805Z","shell.execute_reply.started":"2025-01-31T06:10:23.840197Z","shell.execute_reply":"2025-01-31T06:10:23.853900Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:03:44.970722Z","iopub.execute_input":"2025-01-31T06:03:44.971079Z","iopub.status.idle":"2025-01-31T06:03:44.976932Z","shell.execute_reply.started":"2025-01-31T06:03:44.971053Z","shell.execute_reply":"2025-01-31T06:03:44.976091Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"(700, 8)"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"y.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:03:47.801236Z","iopub.execute_input":"2025-01-31T06:03:47.801572Z","iopub.status.idle":"2025-01-31T06:03:47.806333Z","shell.execute_reply.started":"2025-01-31T06:03:47.801544Z","shell.execute_reply":"2025-01-31T06:03:47.805358Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(700,)"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:03:48.268572Z","iopub.execute_input":"2025-01-31T06:03:48.268881Z","iopub.status.idle":"2025-01-31T06:03:48.274637Z","shell.execute_reply.started":"2025-01-31T06:03:48.268859Z","shell.execute_reply":"2025-01-31T06:03:48.273711Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n          37.88      , -122.23      ],\n       [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n          37.86      , -122.22      ],\n       [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n          37.85      , -122.24      ],\n       ...,\n       [   2.6464    ,   37.        ,    3.95469256, ...,    2.52750809,\n          37.69      , -122.11      ],\n       [   3.4643    ,   42.        ,    4.76375405, ...,    2.48543689,\n          37.69      , -122.11      ],\n       [   2.3973    ,   10.        ,    4.71822034, ...,    2.41525424,\n          37.69      , -122.12      ]])"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Importing necessary libraries\nfrom sklearn.linear_model import LinearRegression  # Linear Regression for regression tasks\nfrom sklearn.tree import DecisionTreeRegressor  # Decision Tree Regressor for regression tasks\nfrom sklearn.svm import SVR  # Support Vector Regressor for regression tasks\nfrom sklearn.model_selection import cross_val_score  # For performing cross-validation\n\n# Initializing the individual regression models\nlr = LinearRegression()  # Linear Regression model (simple regression)\ndt = DecisionTreeRegressor()  # Decision Tree Regressor model\nsvr = SVR()  # Support Vector Regressor model\n\n# Creating a list of estimators, associating each model with a name\nestimators = [('lr', lr), ('dt', dt), ('svr', svr)]  # List of tuples (model name, model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:03:48.799950Z","iopub.execute_input":"2025-01-31T06:03:48.800291Z","iopub.status.idle":"2025-01-31T06:03:49.152411Z","shell.execute_reply.started":"2025-01-31T06:03:48.800261Z","shell.execute_reply":"2025-01-31T06:03:49.151734Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"\n### **Explanation**\n1. **`from sklearn.linear_model import LinearRegression`**\n   - Imports the **LinearRegression** model from the `sklearn` library.\n   - **Linear Regression** is used for predicting a continuous target variable based on one or more independent variables (predictors).\n\n2. **`from sklearn.tree import DecisionTreeRegressor`**\n   - Imports the **DecisionTreeRegressor** model from the `sklearn` library.\n   - **Decision Trees** are used for regression tasks where the model splits data into subsets to predict the target variable.\n\n3. **`from sklearn.svm import SVR`**\n   - Imports the **SVR (Support Vector Regressor)** from the `sklearn` library.\n   - **SVR** is used for regression tasks where the model tries to fit the best hyperplane to predict a continuous target variable, focusing on maximizing the margin while allowing for some errors.\n\n4. **`from sklearn.model_selection import cross_val_score`**\n   - Imports the **cross_val_score** function, which helps evaluate the model by performing **cross-validation** (splitting the data into multiple subsets to ensure model reliability).\n\n5. **Model Initialization (`lr`, `dt`, `svr`)**\n   - **`lr`**: Initializes a **Linear Regression** model.\n   - **`dt`**: Initializes a **Decision Tree Regressor** model.\n   - **`svr`**: Initializes a **Support Vector Regressor** model.\n\n6. **Creating the `estimators` List**\n   - The `estimators` list is a collection of tuples, each containing:\n     - The model's name (as a string), e.g., `'lr'` for Linear Regression.\n     - The model object itself, e.g., `lr` for the Linear Regression instance.\n   - This allows you to loop through different models in a consistent way and evaluate their performance.\n\n---\n\n### **Purpose**\n- **Sets up different regression models** (Linear Regression, Decision Tree, and Support Vector Regressor) to compare their performance on a regression task.\n- Uses the **`estimators` list** to store these models with their names for easy iteration and evaluation.\n\n---\n\n### **Significance**\n- **Multiple models** are initialized to explore which one works best for the given data and task.\n- Using **cross-validation** later (not shown here) allows you to reliably compare the performance of each model.\n- **Different models** (Linear, Tree-based, and SVM) have distinct strengths, and testing them together can reveal which one is most suitable for the data.","metadata":{}},{"cell_type":"code","source":"# Looping through each estimator in the 'estimators' list\nfor estimator in estimators:\n    \n    # Performing 10-fold cross-validation using R² as the scoring metric\n    scores = cross_val_score(estimator[1], X, y, scoring='r2', cv=10)  \n    \n    # Printing the name of the model and the mean R² score (rounded to 2 decimal places)\n    print(estimator[0], np.round(np.mean(scores), 2))  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:03:51.199244Z","iopub.execute_input":"2025-01-31T06:03:51.199575Z","iopub.status.idle":"2025-01-31T06:03:51.684435Z","shell.execute_reply.started":"2025-01-31T06:03:51.199547Z","shell.execute_reply":"2025-01-31T06:03:51.683657Z"}},"outputs":[{"name":"stdout","text":"lr 0.35\ndt 0.09\nsvr -0.62\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"\n### **Explanation**\n1. **`for estimator in estimators:`**\n   - Loops through each model in the `estimators` list, where each element is a tuple.\n   - `estimator[0]`: The model's name (e.g., `'lr'`, `'dt'`, `'svr'`).\n   - `estimator[1]`: The actual model object (e.g., `LinearRegression()`, `DecisionTreeRegressor()`, `SVR()`).\n\n2. **`scores = cross_val_score(estimator[1], X, y, scoring='r2', cv=10)`**\n   - **`cross_val_score`** performs **10-fold cross-validation** on the model (`estimator[1]`).\n   - **`X`**: The features (input data).\n   - **`y`**: The target (output variable).\n   - **`scoring='r2'`**: The performance is evaluated using the **R² (coefficient of determination)** metric, which measures how well the model fits the data (the higher, the better).\n   - **`cv=10`**: Specifies that **10-fold cross-validation** is used to split the data into 10 parts, training and testing the model 10 times.\n\n3. **`print(estimator[0], np.round(np.mean(scores), 2))`**\n   - Prints the model name (`estimator[0]`) and the **mean R² score** (calculated as the average of the R² scores across all 10 folds).\n   - **`np.round(np.mean(scores), 2)`**: Rounds the mean R² score to 2 decimal places for readability.\n\n---\n\n### **Purpose**\n- **Evaluates the performance** of different regression models (Linear Regression, Decision Tree Regressor, and Support Vector Regressor) using **cross-validation**.\n- **Uses R²** as the scoring metric, which is commonly used for regression tasks to evaluate model accuracy.\n- **Compares the models** based on their R² values to determine which performs best.\n\n---\n\n### **Significance**\n- **R² score** indicates how well the model explains the variability of the target variable:\n  - **R² = 1** means perfect fit.\n  - **R² = 0** means the model performs no better than simply predicting the mean of the target variable.\n  - **Negative R²** indicates that the model is worse than simply predicting the mean.\n- **Cross-validation** ensures that the model performance is consistent across different subsets of data, providing more reliable results.\n- This process helps **identify the most suitable model** for the regression task and whether more complex models like Decision Trees or Support Vector Regressors perform better than simpler ones like Linear Regression.\n\n","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import VotingRegressor\n\n# Creating a Voting Regressor using the individual estimators\nvr = VotingRegressor(estimators)  \n\n# Performing 10-fold cross-validation on the Voting Regressor using R² as the scoring metric\nscores = cross_val_score(vr, X, y, scoring='r2', cv=10)  \n\n# Printing the mean R² score of the Voting Regressor (rounded to 2 decimal places)\nprint(\"Voting Regressor\", np.round(np.mean(scores), 2))  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:05:36.689252Z","iopub.execute_input":"2025-01-31T06:05:36.689552Z","iopub.status.idle":"2025-01-31T06:05:37.160611Z","shell.execute_reply.started":"2025-01-31T06:05:36.689521Z","shell.execute_reply":"2025-01-31T06:05:37.159786Z"}},"outputs":[{"name":"stdout","text":"Voting Regressor 0.32\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"\n### **Explanation**\n1. **`vr = VotingRegressor(estimators)`**\n   - Creates a **Voting Regressor (`vr`)** that combines the predictions of multiple regression models (the estimators in the `estimators` list).\n   - The Voting Regressor will use **averaging** to combine the predictions of the individual models. It uses the predicted values of each model, averaging them to make the final prediction.\n\n2. **`scores = cross_val_score(vr, X, y, scoring='r2', cv=10)`**\n   - Performs **10-fold cross-validation** on the **Voting Regressor**.\n   - **R²** is used as the evaluation metric (`scoring='r2'`), which will measure the goodness of fit for the model on each fold of the dataset.\n   - The performance scores (R² values) across the 10 folds are stored in the `scores` array.\n\n3. **`print(\"Voting Regressor\", np.round(np.mean(scores), 2))`**\n   - Prints the name of the model (`Voting Regressor`) along with its **mean R² score** (calculated by averaging the scores from the 10 folds).\n   - The R² score is rounded to 2 decimal places for better presentation.\n\n---\n\n### **Purpose**\n- **Evaluates the performance** of the **Voting Regressor**, which combines multiple regression models, by performing **cross-validation**.\n- **Uses R²** as the metric to assess how well the combined predictions fit the data, providing insight into the effectiveness of the ensemble model.\n\n---\n\n### **Significance**\n- **Voting Regressor** combines the strengths of multiple individual regression models, potentially improving predictive performance by reducing model bias or variance.\n- **Cross-validation** provides a more reliable measure of the model's generalization ability by testing it on different subsets of the data.\n- **R² score** offers a clear indication of how well the Voting Regressor is able to explain the variation in the target variable, with a higher score indicating better model performance.\n\n","metadata":{}},{"cell_type":"code","source":"# Iterating through possible weight combinations (1, 2, and 3 for each estimator)\nfor i in range(1, 4):  \n    for j in range(1, 4):  \n        for k in range(1, 4):  \n            \n            # Creating a Voting Regressor with specific weights for each estimator\n            vr = VotingRegressor(estimators, weights=[i, j, k])  \n            \n            # Performing 10-fold cross-validation on the Voting Regressor with R² as the scoring metric\n            scores = cross_val_score(vr, X, y, scoring='r2', cv=10)  \n            \n            # Printing the combination of weights (i, j, k) and the mean R² score (rounded to 2 decimal places)\n            print(\"For i={},j={},k={}\".format(i, j, k), np.round(np.mean(scores), 2))  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:06:34.977668Z","iopub.execute_input":"2025-01-31T06:06:34.978034Z","iopub.status.idle":"2025-01-31T06:06:44.671062Z","shell.execute_reply.started":"2025-01-31T06:06:34.978000Z","shell.execute_reply":"2025-01-31T06:06:44.670223Z"}},"outputs":[{"name":"stdout","text":"For i=1,j=1,k=1 0.31\nFor i=1,j=1,k=2 0.17\nFor i=1,j=1,k=3 0.07\nFor i=1,j=2,k=1 0.36\nFor i=1,j=2,k=2 0.27\nFor i=1,j=2,k=3 0.19\nFor i=1,j=3,k=1 0.32\nFor i=1,j=3,k=2 0.3\nFor i=1,j=3,k=3 0.26\nFor i=2,j=1,k=1 0.36\nFor i=2,j=1,k=2 0.26\nFor i=2,j=1,k=3 0.17\nFor i=2,j=2,k=1 0.36\nFor i=2,j=2,k=2 0.3\nFor i=2,j=2,k=3 0.23\nFor i=2,j=3,k=1 0.38\nFor i=2,j=3,k=2 0.34\nFor i=2,j=3,k=3 0.27\nFor i=3,j=1,k=1 0.37\nFor i=3,j=1,k=2 0.3\nFor i=3,j=1,k=3 0.23\nFor i=3,j=2,k=1 0.42\nFor i=3,j=2,k=2 0.34\nFor i=3,j=2,k=3 0.27\nFor i=3,j=3,k=1 0.4\nFor i=3,j=3,k=2 0.36\nFor i=3,j=3,k=3 0.31\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"\n\n### **Explanation**\n1. **`for i in range(1, 4):`**\n   - This loop iterates over values for the first weight (`i`), ranging from 1 to 3. Each value represents a weight for the first estimator in the `estimators` list (e.g., Linear Regression).\n\n2. **`for j in range(1, 4):`**\n   - Similarly, this loop iterates over values for the second weight (`j`), representing a weight for the second estimator in the `estimators` list (e.g., Decision Tree Regressor).\n\n3. **`for k in range(1, 4):`**\n   - This loop iterates over values for the third weight (`k`), representing a weight for the third estimator in the `estimators` list (e.g., Support Vector Regressor).\n\n4. **`vr = VotingRegressor(estimators, weights=[i, j, k])`**\n   - The `Voting Regressor` is created with **custom weights** for each model (based on `i`, `j`, and `k`).\n   - The `weights` list determines how much influence each model's prediction has on the final output of the ensemble. Higher weights give more influence to a specific model.\n\n5. **`scores = cross_val_score(vr, X, y, scoring='r2', cv=10)`**\n   - **10-fold cross-validation** is performed on the **Voting Regressor** (`vr`).\n   - **R²** is used as the evaluation metric to measure how well the model explains the variance in the target variable (`y`).\n\n6. **`print(\"For i={},j={},k={}\".format(i, j, k), np.round(np.mean(scores), 2))`**\n   - Prints the current weight combination (`i`, `j`, `k`) and the **mean R² score** obtained from the 10 folds.\n   - The R² score is rounded to 2 decimal places for readability.\n\n---\n\n### **Purpose**\n- **Explores different weight combinations** for the estimators in the **Voting Regressor** to determine which weighting scheme provides the best performance.\n- **Evaluates each weight combination** using **cross-validation** to ensure a reliable measure of the model’s generalization performance.\n- **R²** is used as the metric to assess the fit of the model.\n\n---\n\n### **Significance**\n- **Custom weights** allow each estimator in the **Voting Regressor** to contribute differently to the final prediction, enabling you to experiment and potentially improve the model's performance.\n- **Cross-validation** ensures that the evaluation is robust and not dependent on a single train-test split, providing a more reliable performance estimate.\n- The goal is to find the best combination of weights that maximizes the model’s performance, as indicated by the **R² score**, and improves the overall accuracy of the **Voting Regressor**.\n\n","metadata":{}},{"cell_type":"code","source":"# Defining a list of Decision Tree Regressors with different maximum depths\ndt1 = DecisionTreeRegressor(max_depth=1)  \ndt2 = DecisionTreeRegressor(max_depth=3)  \ndt3 = DecisionTreeRegressor(max_depth=5)  \ndt4 = DecisionTreeRegressor(max_depth=7)  \ndt5 = DecisionTreeRegressor(max_depth=None)  \n\n# Creating a list of tuples where each tuple contains the model name and the model itself\nestimators = [('dt1', dt1), ('dt2', dt2), ('dt3', dt3), ('dt4', dt4), ('dt5', dt5)]  \n\n# Looping through each estimator in the 'estimators' list\nfor estimator in estimators:\n    \n    # Performing 10-fold cross-validation using R² as the scoring metric\n    scores = cross_val_score(estimator[1], X, y, scoring='r2', cv=10)  \n    \n    # Printing the name of the model and the mean R² score (rounded to 2 decimal places)\n    print(estimator[0], np.round(np.mean(scores), 2))  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:08:26.045406Z","iopub.execute_input":"2025-01-31T06:08:26.045718Z","iopub.status.idle":"2025-01-31T06:08:26.201505Z","shell.execute_reply.started":"2025-01-31T06:08:26.045698Z","shell.execute_reply":"2025-01-31T06:08:26.200662Z"}},"outputs":[{"name":"stdout","text":"dt1 -0.01\ndt2 0.21\ndt3 0.22\ndt4 0.14\ndt5 0.15\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"\n### **Explanation**\n1. **`dt1 = DecisionTreeRegressor(max_depth=1)`** through **`dt5 = DecisionTreeRegressor(max_depth=None)`**\n   - Defines a list of five **Decision Tree Regressor** models with different maximum depths:\n     - **`max_depth=1`**: A very shallow tree (underfitting, simple model).\n     - **`max_depth=3`** to **`max_depth=7`**: Increasing depths, which means the tree becomes more complex (potentially overfitting).\n     - **`max_depth=None`**: The tree grows until all leaves are pure (maximal complexity).\n\n2. **`estimators = [('dt1', dt1), ('dt2', dt2), ('dt3', dt3), ('dt4', dt4), ('dt5', dt5)]`**\n   - This creates a list of tuples, where each tuple contains the model’s name and the corresponding model object. This structure is useful for iterating over the models.\n\n3. **`for estimator in estimators:`**\n   - Iterates over each estimator in the `estimators` list.\n   - For each estimator, the loop will perform cross-validation and print the results.\n\n4. **`scores = cross_val_score(estimator[1], X, y, scoring='r2', cv=10)`**\n   - Performs **10-fold cross-validation** on the current model (`estimator[1]`).\n   - **R²** is used as the scoring metric to evaluate the model’s performance. R² tells us how well the model explains the variance of the target variable.\n   - **`X`** is the input features, and **`y`** is the target variable.\n\n5. **`print(estimator[0], np.round(np.mean(scores), 2))`**\n   - Prints the name of the model (`estimator[0]`) and its **mean R² score** (calculated by averaging the R² scores across all 10 folds).\n   - **`np.round(np.mean(scores), 2)`** rounds the mean R² score to 2 decimal places for better readability.\n\n---\n\n### **Purpose**\n- **Evaluates the performance** of different **Decision Tree Regressors** with varying maximum depths using **cross-validation**.\n- The **R² score** is used as the evaluation metric to measure the fit of each model, providing an indicator of how well each tree explains the variance in the target variable.\n\n---\n\n### **Significance**\n- **Varying the depth of the Decision Tree** can have a significant effect on its performance:\n  - **Shallow trees (max_depth=1)** tend to underfit the data, leading to poor performance.\n  - **Deeper trees (max_depth=7 or None)** may overfit the data, capturing noise and leading to a lower generalization ability.\n  - **Balanced trees** (intermediate depths) might strike a better trade-off between bias and variance, leading to better generalization.\n- **Cross-validation** ensures that the model's performance is not overly dependent on a single train-test split, giving a more reliable estimate of how well the model will perform on unseen data.\n- **R² score** helps in determining which depth of the tree best explains the variability in the target variable. A higher R² score indicates a better model fit.\n\n","metadata":{}},{"cell_type":"code","source":"# Creating a Voting Regressor with a list of estimators\nvr = VotingRegressor(estimators)\n\n# Performing 10-fold cross-validation using R² as the scoring metric\nscores = cross_val_score(vr, X, y, scoring='r2', cv=10)\n\n# Printing the mean R² score of the Voting Regressor (rounded to 2 decimal places)\nprint(\"Voting Regressor\", np.round(np.mean(scores), 2))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T06:09:24.363454Z","iopub.execute_input":"2025-01-31T06:09:24.363788Z","iopub.status.idle":"2025-01-31T06:09:24.504266Z","shell.execute_reply.started":"2025-01-31T06:09:24.363764Z","shell.execute_reply":"2025-01-31T06:09:24.503240Z"}},"outputs":[{"name":"stdout","text":"Voting Regressor 0.39\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"\n\n### **Purpose**\n- Evaluate the **Voting Regressor** model using **10-fold cross-validation** and the **R² score** to assess its performance.\n\n---\n\n### **Significance**\n- **Voting Regressor** combines multiple models to make predictions, which can improve performance by leveraging the strengths of different algorithms.\n- **R²** measures how well the ensemble model explains the variance in the target variable.\n- **Cross-validation** ensures a robust evaluation by testing the model on different data splits.\n\n---\n\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}